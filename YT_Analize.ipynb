{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Playlists.cvs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import glob\n",
    "file_paths = glob.glob(\".\\data\\*.csv\")\n",
    "\n",
    "dfs = [] # an empty list to store the data frames\n",
    "for file_path in file_paths:\n",
    "    data = pd.read_csv (file_path)\n",
    "    data['playlist_name'] = os.path.basename(file_path).split('.')[-2]\n",
    "    dfs.append(data) # append the data frame to the list\n",
    "\n",
    "videos = pd.concat(dfs, ignore_index=True) # concatenate all the data frames in the list.\n",
    "\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = videos.set_axis([\"video_id\", \"video_date\", 'playlist_name'], axis=1)\n",
    "videos['video_id'] = videos['video_id'].apply(lambda x: str(x).strip())\n",
    "videos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GOOGLE API - request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from SECRETS import YOUTUBE_API_KEY\n",
    "import json\n",
    "API_KEY = YOUTUBE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "def get_video_info(id):\n",
    "    request = youtube.videos().list(\n",
    "        part='snippet,contentDetails,statistics,topicDetails,localizations', \n",
    "        id=id\n",
    "        )\n",
    "    return request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['res'] = videos['video_id'].apply(get_video_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data from playlist.csv and GOOGLE API response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist added date - from playlist.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_date(string):\n",
    "    return pd.to_datetime(string[:-4], dayfirst=True)\n",
    "def get_month(date):\n",
    "    return int(date.month)\n",
    "def get_year(date):\n",
    "    return int(date.year)\n",
    "def get_weekday(date):\n",
    "    return date.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['video_date'] = videos['video_date'].apply(string_to_date)\n",
    "videos['video_date_m'] = videos['video_date'].apply(get_month)\n",
    "videos['video_date_y'] = videos['video_date'].apply(get_year)\n",
    "videos['video_date_w'] = videos['video_date'].apply(get_weekday)\n",
    "# videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video info - from Google Api response:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic text info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_title(info):\n",
    "    for item in info['items']:\n",
    "        return item['snippet']['title']\n",
    "              \n",
    "def get_video_description(info):\n",
    "    for item in info['items']:\n",
    "        return item['snippet']['description']\n",
    "\n",
    "def get_video_channel(info):\n",
    "    for item in info['items']:\n",
    "        return item['snippet']['channelTitle']\n",
    "\n",
    "def get_video_topicCategories(info):\n",
    "    for item in info['items']:\n",
    "        if (topicDetails := item.get('topicDetails')) != None:\n",
    "            return topicDetails.get('topicCategories')\n",
    "\n",
    "def get_video_AudioLanguage(info):\n",
    "    for item in info['items']:\n",
    "        return item['snippet'].get('defaultAudioLanguage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['video_title'] = videos['res'].apply(get_video_title)\n",
    "videos['video_description'] = videos['res'].apply(get_video_description)\n",
    "videos['video_channel'] = videos['res'].apply(get_video_channel)\n",
    "videos['video_topic'] = videos['res'].apply(get_video_topicCategories)\n",
    "videos['video_lang'] = videos['res'].apply(get_video_AudioLanguage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import isodate\n",
    "def get_video_len(info):\n",
    "    for item in info['items']:\n",
    "        return isodate.parse_duration(item['contentDetails']['duration'])\n",
    "\n",
    "def deltatime_to_seconds(len):\n",
    "    return len.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['video_len'] = videos['res'].apply(get_video_len)\n",
    "videos['video_len_s'] = videos['video_len'].apply(deltatime_to_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viewCount(info):\n",
    "    for item in info['items']:\n",
    "        if (statistics := item.get('statistics')) != None:\n",
    "            return statistics.get('viewCount')\n",
    "def get_likeCount(info):\n",
    "    for item in info['items']:\n",
    "        if (statistics := item.get('statistics')) != None:\n",
    "            return statistics.get('likeCount')\n",
    "def get_commentCount(info):\n",
    "    for item in info['items']:\n",
    "        if (statistics := item.get('statistics')) != None:\n",
    "            return statistics.get('commentCount')\n",
    "def to_int(string):\n",
    "    if string != None:\n",
    "        return int(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['video_viewCount'] = videos['res'].apply(get_viewCount)\n",
    "videos['video_likeCount'] = videos['res'].apply(get_likeCount)\n",
    "videos['video_commentCount'] = videos['res'].apply(get_commentCount)\n",
    "\n",
    "videos['video_viewCount'] = videos['video_viewCount'].apply(to_int)\n",
    "videos['video_likeCount'] = videos['video_likeCount'].apply(to_int)\n",
    "videos['video_commentCount'] = videos['video_commentCount'].apply(to_int)\n",
    "\n",
    "videos\n",
    "# videos[['tytul', 'viewCount', 'likeCount', 'commentCount']].sort_values('viewCount', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Spotify API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from SECRETS import SPOTIFY_CLIENT_ID, SPOTIFY_CLIENT_SECRET, SPOTIFY_REDIRECT_URI\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=SPOTIFY_CLIENT_ID, client_secret=SPOTIFY_CLIENT_SECRET, redirect_uri=SPOTIFY_REDIRECT_URI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spotify_data(vid):\n",
    "    # print(vid)\n",
    "    if vid['video_title'] == None:\n",
    "        # print('')\n",
    "        # print('')\n",
    "        # print({})\n",
    "        # print([])\n",
    "        return None,None\n",
    "    # q = str(vid['video_title'])\n",
    "    for q in [vid['video_title'] + ' ' + vid['video_channel'], vid['video_title']]:\n",
    "        search_results = sp.search(q, limit=10, offset=0, type='track', market=None)\n",
    "        if len(search_results['tracks']['items']):\n",
    "            track_id = search_results['tracks']['items'][0][\"id\"]\n",
    "\n",
    "            audio_features_results = sp.audio_features(tracks=[track_id])[0]\n",
    "            if audio_features_results != None:\n",
    "                track_features = dict((key, audio_features_results[key]) for key in ['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo'])\n",
    "                track_features['popularity'] = search_results['tracks']['items'][0][\"popularity\"]\n",
    "            else:\n",
    "                track_features = {}\n",
    "            artist_id = search_results['tracks']['items'][0][\"artists\"][0][\"id\"]\n",
    "            track_author = sp.artist(artist_id)\n",
    "            track_genre = track_author[\"genres\"]\n",
    "\n",
    "            # print(vid['video_title'] + ' ' + vid['video_channel'])\n",
    "            # print(search_results['tracks']['items'][0][\"name\"] +' - ' + search_results['tracks']['items'][0][\"artists\"][0][\"name\"])\n",
    "            # print(track_features)\n",
    "            # print(track_genre)\n",
    "\n",
    "            return track_features, track_genre\n",
    "    # print(vid['video_title'] + ' ' + vid['video_channel'])\n",
    "    # print('')\n",
    "    # print({})\n",
    "    # print([])\n",
    "    return None,None\n",
    "\n",
    "videos['video_features'], videos['video_genre'] = zip(*videos[['video_title', 'video_channel']].apply(get_spotify_data, axis=1))\n",
    "# poki = videos[['video_title','video_channel']].apply(get_spotify_data, axis=1)\n",
    "#  videos[['video_features', 'video_genre']]\n",
    "videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos[['playlist_name','video_title', 'video_channel', 'video_genre', 'video_features']].to_excel('OUTPUT.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Play history\n",
    "## Load history + clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_json('data\\history.json')\n",
    "history = history.drop(['header','products','details','description', 'activityControls', 'subtitles'], axis=1, errors='ignore')\n",
    "history = history.rename(columns = {'time':'date'})\n",
    "history = history.rename(columns=lambda x: 'history_'+x)\n",
    "history = history[history['history_titleUrl'].notna()]\n",
    "history.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(url):\n",
    "    return str(url.replace('https://www.youtube.com/watch?v=', ''))\n",
    "def extract_clear_title(title):\n",
    "    return title.replace('Obejrzano: ', '')\n",
    "def string_to_date_history(string):\n",
    "    return pd.to_datetime(string[:10])\n",
    "\n",
    "history['history_video_id'] = history['history_titleUrl'].apply(extract_id)\n",
    "# history = history.drop(['history_titleUrl'], axis=1)\n",
    "\n",
    "history['history_title'] = history['history_title'].apply(extract_clear_title)\n",
    "\n",
    "history['history_date'] = history['history_date'].apply(string_to_date_history)\n",
    "history['history_date_m'] = history['history_date'].apply(get_month)\n",
    "history['history_date_y'] = history['history_date'].apply(get_year)\n",
    "history['history_date_w'] = history['history_date'].apply(get_weekday)\n",
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  JOIN - watch_history + playlist \n",
    "\n",
    "## Łączenie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_history = pd.merge(\n",
    "    history,\n",
    "    videos,\n",
    "    how=\"right\",\n",
    "    left_on='history_video_id',\n",
    "    right_on='video_id',\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=False,\n",
    "    suffixes=(\"_history\", \"_videos\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "playlist_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Analysis and graph generate \\<in progress\\> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music on playlist analysis\n",
    "### Num. of songs on each playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = videos\n",
    "to_plot = to_plot.groupby(['playlist_name']).count().filter(items=['video_id']).sort_values('video_id')\n",
    "# print(to_plot)\n",
    "to_plot = to_plot.plot(kind='bar',figsize = (12, 6), style='o-.', ylabel='count_video_id', title='Num. of songs on each playlist')\n",
    "to_plot = to_plot.bar_label(to_plot.containers[0], fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num. of songs in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = videos\n",
    "to_plot = to_plot.groupby(['video_date_y', 'playlist_name'])\n",
    "to_plot = to_plot.count().filter(items=['video_id'])\n",
    "to_plot = to_plot.unstack()\n",
    "to_plot.plot(kind='line',figsize = (12, 6), style='o-.', ylabel='count_video_id', grid=True, title = 'Num. of song added in each year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num. of song added in given date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = videos\n",
    "to_plot = to_plot.groupby(['video_date_y','video_date_m', 'playlist_name'])\n",
    "to_plot = to_plot.count().filter(items=['video_id'])#.unstack()\n",
    "to_plot = to_plot.unstack()\n",
    "to_plot.plot(kind='line',figsize = (25, 12), style='o--', ylabel='count_video_id', grid=True, title = 'Num. of song added in given date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num. of song added in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = videos\n",
    "to_plot = to_plot.groupby(['video_date_m', 'playlist_name'])\n",
    "to_plot = to_plot.count().filter(items=['video_id'])#.unstack()\n",
    "to_plot = to_plot.unstack()\n",
    "to_plot\n",
    "to_plot.plot(kind='line',figsize = (12, 6),  style='o-.', ylabel='count_video_id', grid=True, title = 'Num. of song added in each month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num. of song added by week day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "to_plot = videos.groupby(['video_date_w', 'playlist_name'])\n",
    "to_plot.count().reindex(cats, level='video_date_w')[['video_id']].unstack().plot(kind='line',figsize = (16, 9),style='o-.', ylabel='count_video_id', grid=True, title = 'Num. of song added by weekday')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most play video_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = videos.groupby(['video_channel'])\n",
    "to_plot.count()[['video_id']].sort_values('video_id', ascending=False) #.plot(kind='line',figsize = (16, 9),style='o-.', ylabel='count_video_id', grid=True, title = 'Num. of song added by weekday')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top of 'video_len_s', 'video_likeCount', 'video_viewCount', 'video_commentCount', 'ratios' and mean of playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by one of 'video_len_s', 'video_likeCount', 'video_viewCount', 'video_commentCount'\n",
    "q = videos\n",
    "q['l/v_ratio'] = q['video_likeCount'] / q['video_viewCount']\n",
    "q['c/v_ratio'] = q['video_commentCount'] / q['video_viewCount']\n",
    "q['c/l_ratio'] = q['video_commentCount'] / q['video_likeCount']\n",
    "q = q[['video_id','playlist_name','video_title', 'video_channel', 'video_len_s', 'video_likeCount', 'video_viewCount', 'video_commentCount', 'l/v_ratio', 'c/l_ratio', 'c/v_ratio']].dropna(subset=['video_title'])\n",
    "top_of = 'c/l_ratio'\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 50000): \n",
    "    print(q.dropna(subset=[top_of]).sort_values(top_of, ascending = False))\n",
    "\n",
    "q.groupby('playlist_name').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by given music feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_series(x):\n",
    "    print(x)\n",
    "    return pd.Series(x)\n",
    "features = videos\n",
    "\n",
    "SORT_BY = 'video_feature_acousticness'\n",
    "\n",
    "for index in features.index:\n",
    "    dic = features.loc[index,'video_features']\n",
    "    if dic != None:  \n",
    "        for k, v in dic.items():\n",
    "            features.loc[index,'video_feature_' + k] = v\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 50000): \n",
    "    print(features[features['playlist_name'] == 'Ex1'][['video_title',SORT_BY]].dropna().sort_values(SORT_BY, ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean for given feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.groupby(['playlist_name']).mean().filter(items=['video_feature_danceability',\t'video_feature_energy',\t'video_feature_speechiness'\t,'video_feature_acousticness',\t'video_feature_instrumentalness',\t'video_feature_liveness','video_feature_valence','video_feature_tempo','video_feature_popularity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count genres for each playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos['video_genre']\n",
    "\n",
    "def to_series(x):\n",
    "    print(x)\n",
    "    return pd.Series(x)\n",
    "genres = videos\n",
    "df_list = []\n",
    "\n",
    "for index in genres.index:\n",
    "    li = genres.loc[index,'video_genre']\n",
    "    if li != None:  \n",
    "        for val in li:\n",
    "            df = list(genres.loc[index,['video_id', 'video_title', 'playlist_name']]) + [val]\n",
    "            df_list.append(pd.DataFrame([df], columns=['video_id', 'video_title', 'playlist_name', 'video_genre']))\n",
    "\n",
    "genres_ans = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 50000): \n",
    "    print(genres_ans.groupby(['playlist_name', 'video_genre']).count()['video_id'].unstack().unstack().unstack().fillna(0).sort_values('📼 Tapes Colection 📼', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history + videos graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### play count by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = playlist_history.dropna(subset=['history_date_y'])\n",
    "to_plot['history_date_y'] = to_plot['history_date_y'].astype('int64')\n",
    "to_plot['history_date_y'] = to_plot['history_date_y'].astype('str')\n",
    "# to_plot\n",
    "to_plot = to_plot.groupby(['history_date_y', 'playlist_name'])\n",
    "to_plot = to_plot.count()['video_id']\n",
    "to_plot = to_plot.unstack()\n",
    "to_plot = to_plot.plot(kind='line',figsize = (12, 6), style='o-.', ylabel='count_hisotry_play', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most played music in given year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2022\n",
    "ans = playlist_history.groupby(['history_date_y', 'video_title'])\n",
    "ans = ans.count().sort_values(['history_date_y', 'video_id'], ascending=False)\n",
    "ans = ans.unstack()['video_id'].unstack().unstack()\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    print(ans.sort_values(YEAR,ascending = False)[YEAR])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most played music of all time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk = playlist_history.groupby(['video_title'])\n",
    "wynik = gk.count().sort_values(['video_id'], ascending=False)['video_id']\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(wynik)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nieogladniete = playlist_history[playlist_history['history_video_id'].isna()]\n",
    "nieogladniete = nieogladniete.drop_duplicates(subset = ['video_id'])\n",
    "nieogladniete[['video_title', 'video_id',  'video_channel', 'history_video_id', 'history_titleUrl']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top played genres in given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_history['video_genre']\n",
    "\n",
    "def to_series(x):\n",
    "    print(x)\n",
    "    return pd.Series(x)\n",
    "genres = playlist_history\n",
    "df_list = []\n",
    "\n",
    "for index in genres.index:\n",
    "    li = genres.loc[index,'video_genre']\n",
    "    if li != None:  \n",
    "        for val in li:\n",
    "            df = list(genres.loc[index,['video_id', 'video_title', 'playlist_name', 'history_date_y']]) + [val]\n",
    "            df_list.append(pd.DataFrame([df], columns=['video_id', 'video_title', 'playlist_name', 'video_genre', 'history_date_y']))\n",
    "\n",
    "genres_ans = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022.0\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 50000): \n",
    "    print(genres_ans.groupby(['playlist_name','history_date_y', 'video_genre']).count()['video_id'].unstack().fillna(0).reset_index().rename_axis(None, axis=1)[['history_date_y', year]].sort_values(year, ascending=False)) #.sort_values('2022.0', ascending=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
